<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  
  <!--[if lt IE 9]>
  <script src="/lib/html5shim.js"></script>
  <![endif]-->  
  
  <!-- These are some core styles the slideshow app requires -->
  <link rel="stylesheet" href="/lib/styles.css" />
  
  <!-- These are the styles you'll add to make the slides look great -->
  <link rel="stylesheet" href="/css/styles.css" />
  
  <title>Low Level C [Part 1]</title>
</head>
<body>
  <header>
      <h1>Low Level C [Part 1]</h1>
    <nav>
      <ul>
        <li><button id="prev-btn" title="Previous slide">Previous Slide</button></li>
        <li><span id="slide-number"></span>/<span id="slide-total"></span></li>
        <li><button id="next-btn" title="Next Slide">Next Slide</button></li>
      </ul>
    </nav>
  </header>
  <div id="deck">
    
    <!-- Begin slides -->
    <section>
      <hgroup>
        <h1>C for Exploitation</h1>
        <h2>An Introduction to Low Level C</h2>
      </hgroup>
      <p>
      C is an interesting language because it is the foundation of most
      operating systems.  Many servers and low level systems libraries are
      written in it, kernels are written in it, and lots of higher-level
      languages compile down to something compatible with the C ABI.
      Exploitation often involvs taking advantage of assumptions that are
      not true at the low level, so it is essential that you have a solid
      understanding of C at its lowest level.
      </p>
    </section>
    <section>
      <hgroup>
        <h1>Data Types</h1>
        <h2>(Assuming 32-bit Linux)</h2>
      </hgroup>
      <table><tbody>
          <tr> <td> Type        </td> <td> Width (bytes) </td> </tr>
          <tr> <td> bool        </td> <td> 1             </td> </tr>
          <tr> <td> char        </td> <td> 1             </td> </tr>
          <tr> <td> short       </td> <td> 2             </td> </tr>
          <tr> <td> int         </td> <td> 4             </td> </tr>
          <tr> <td> long        </td> <td> 4             </td> </tr>
          <tr> <td> long long   </td> <td> 8             </td> </tr>
          <tr> <td> float       </td> <td> 4             </td> </tr>
          <tr> <td> double      </td> <td> 8             </td> </tr>
          <tr> <td> pointer     </td> <td> 4             </td> </tr>
          <tr> <td> instruction </td> <td> (variable)    </td> </tr>
      </tbody></table>
    </section>
    <section>
      <hgroup>
        <h1>Negative Numbers</h1>
        <h2>How do we represent negative quantities in binary?</h2>
      </hgroup>
      <p>There are three primary ways to represent negative numbers: </p>
      <ul>
          <li>Sign + Magnitude: Not used in real hardware</li>
          <li>One's Complement: Invert all the bits</li>
          <li>Two's Complement: Invert all the bits, and add 1</li>
      </ul>
      <br />
      <p>Of these, two's complement is the most common.  One's complement
      negation is sometimes used with boolean values, though.
      </p>
      <p>Why use two's complement?</p>
      <p>Because it makes math easy!  Let's have a look at -1 + 1 = 0:</p>
      <ul>
          <li>-1 == two's complement of 0001 == 1110 + 1 == 1111 </li>
          <li>1111 + 0001 = 0000 (with overflow), which we expect </li>
          <li>The interested can find a proof <a href='http://en.wikipedia.org/wiki/Two%27s_complement#Why_it_works'>here</a></li>
      </ul>
    </section>
    <section>
      <hgroup>
        <h1>Signed vs. Unsigned</h1>
      </hgroup>
      <p>
        Usually, when dealing with integers to perform computations on
        data, we want to be able to represent negative quantities.
      </p>
      <p>
        However, when negative values do not make sense, we can choose to
        force the computer to interpret the value as a positive number. To
        do so we use the unsigned integer type (e.g. unsigned int).
      </p>
      <p>Examples of when to use unsigned types:</p>
      <ul>
          <li>Indexes into an array</li>
          <li>Number of bytes to read</li>
          <li>The size of a buffer</li>
          <li>Representing raw, untyped binary data</li>
      </ul>
    </section>
    <section>
      <hgroup>
        <h1>A Note on Signed/Unsigned</h1>
        <h2>Security Concerns</h2>
      </hgroup>
      <p>
        Mishandling signed and unsigned data can cause security
        vulnerabilities because of the differences in range.  For a 1 byte
        integer, there are 256 different values:
      </p>
      <ul>
          <li>signed char: -128 to +127</li>
          <li>unsigned char: 0 to +255</li>
      </ul>
      <br />
      <p>
        Consequently, signed values -128 to -1 are represented the same way
        as unsigned values from +128 to +255.
      </p>
      <p>
        This can cause problems when programmers treat signed data as
        unsigned or vice versa.
      </p>
    </section>    
    <section>
      <hgroup>
        <h1>Endianness</h1>
        <h2>Big vs. Little Endian</h2>
      </hgroup>
      <p>
        There are two ways of ordering the bytes on a computer: big endian
        and little endian.
      </p>
      <ul>
          <li>Big Endian: Most Significant Byte (MSB) first</li>
          <li>Little Endian: LSB first</li>
      </ul>
      <br />
      <p>
        For example, the byte sequence &quot;\x01\x00&quot; represents
        0x0100 (256) on a big endian machine and 0x0001 (1) on a little
        endian machine.
      </p>
      <p>
        A side effect of little endian is that converting a 32-bit integer
        to a 16- or 8-bit integer (or 16- to 8-bit) involves ignoring the
        bytes on the right side, not on the left.  This makes the machine
        code for expressions like <code>short s = *pointer_to_int;</code>
        simpler, since you don't need to add an offset to the address.
      </p>
    </section>
    <section>
        <hgroup>
            <h1>x86 is a Little Endian Architecture!</h1>
        </hgroup>
        <p>
            I promise you that this <b>will</b> mess you up at least
            once when you're writing an exploit!
        </p>
    </section>
    </section>
    <section>
      <hgroup>
        <h1>Shifts and Bitwise Operations</h1>
        <h2>Conceptual</h2>
      </hgroup>
      <p>
        Shifts simply move all of the bits to the right or the left,
        dropping what falls off the end and filling in with zeros.
        The exception to this rule is when right-shifting a signed number.
        In this case, the computer checks if the number is negative by
        looking at the most significant bit.  Positive numbers are filled
        in with zeros, and negative numbers filled in with ones.  This
        process is called <em>sign extension</em>
      </p>
      <ul>
          <li>Right Shift: &gt;&gt;</li>
          <li>Left Shift: &lt;&lt;</li>
      </ul>
      <br />
      <p>
        Bitwise operations apply a logical operation (not, and, or, xor)
        to every bit in order.
      </p>
      <ul>
          <li>Not: ~</li>
          <li>And: &amp;</li>
          <li>Or: |</li>
          <li>Xor: ^</li>
      </ul>
    </section>
    <section>
        <hgroup>
        <h1>Shifts and Bitwise Operations</h1>
        <h2>Examples</h2>
        </hgroup>
        <ul>
            <li>1100 &lt;&lt; 1 == 1000</li>
            <li>1100 (unsigned) &gt;&gt; 1 == 0110</li>
            <li>1100 (signed) &gt;&gt; 1 == 1110</li>
            <li>~1100 == 0011</li>
            <li>1100 &amp; 0000 == 0000</li>
            <li>1100 &amp; 1111 == 1100</li>
            <li>1100 | 0000 == 1100</li>
            <li>1100 | 1111 == 1111</li>
            <li>1100 ^ 0000 == 1100</li>
            <li>1100 ^ 1111 == 0011</li>
        </ul>
    </section>
    <section>
        <hgroup>
        <h1>Floating Point Representation</h1>
        </hgroup>
        <p>
        Floating point numbers are represented according to the standard
        IEEE-754.  That means nothing to you.  Since it isn't critically
        important to you right now, we're going to wave our hands at it.
        Those interested should go to the Wikipedia page.
        </p>
        <p>
        Sufficeth to say it is quite different from how integers are
        represented.
        </p>
    </section>
    <section>
        <hgroup>
        <h1>Type Casts</h1>
        <h2>Types of Casts</h2>
        </hgroup>
        <p>There are two types of casts:</p>
        <ul>
            <li>Normal Casts: <code>float f = (float)some_int;</code></li>
            <li>Binary Reinterpretation Casts:
                <code>float f = *(float*)&amp;some_int;</code></li>
        </ul>
        <br />
        <p>
        Needless to say, the two are quite different.  The first will
        do a proper conversion, while the second will copy the raw bit 
        pattern.
        </p>
        <p>In addition, there are multiple types of normal casts:</p>
        <ul>
            <li>Integer&lt;-&gt;Integer Casts: Narrowing</li>
            <li>Integer&lt;-&gt;Integer Casts: Widening</li>
            <li>Integer&lt;-&gt;Float Casts</li>
            <li>Pointer Casts (which result in reinterpret-casts of
                the data they point to)</li>
        </ul>
    </section>
    <section>
        <hgroup>
        <h1>Type Casts</h1>
        <h2>Integer&lt;-&gt;Integer Casts: Narrowing</h2>
        </hgroup>
        <p>
        Narrowing is casting a larger integer type down to a smaller
        integer type (e.g. int to short).
        </p>
        <p>
        To narrow to n bytes, the machine will take the n least significant
        bytes and store them into the result.  Thus, 
        <code>(char)257 == 1</code>.
        </p>
        <p>
        As shown in the above example, this can cause strange results
        when narrowing to a type that cannot hold the run-time value of
        the variable being cast.  Narrowing casts are <em>only</em> safe
        when the run-time value can be represented in the target type.
        Narrowing in other circumstances causes unintuitive results.
        </p>
    </section>
    <section>
        <hgroup>
        <h1>Type Casts</h1>
        <h2>Integer&lt;-&gt;Integer Casts: Widening</h2>
        </hgroup>
        <p>
        On the other hand, the opposite (widening) is always valid for 
        unsigned-&gt;signed casts and casts with no change in signedness.
        In these cases, the n bytes of the original variable are copied
        to the least significant bytes of the target.  If the target is
        unsigned, zeros are added to the MSBs, and if it is signed then
        they are subject to sign extension.
        </p>
    </section>
    
    <!-- /End slides -->
    
  </div>
  <!-- /deck -->
  <script src="/lib/jquery-1.5.2.min.js"></script>
  <script src="/lib/jquery.jswipe-0.1.2.js"></script>  
  <script src="/lib/htmlSlides.js"></script>
  <script>
    //Do our business when the DOM is ready for us
    $(function() {
      //One little option: hideToolbar (boolean; default = false)
      htmlSlides.init({ hideToolbar: true });
    });
  </script>
  </body>
</html>
